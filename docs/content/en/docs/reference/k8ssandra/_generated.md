

![Version: 0.49.0](https://img.shields.io/badge/Version-0.49.0-informational?style=flat-square) ![Type: application](https://img.shields.io/badge/Type-application-informational?style=flat-square) ![AppVersion: 3.11.10](https://img.shields.io/badge/AppVersion-3.11.10-informational?style=flat-square)

## Maintainers

| Name | Email | Url |
| ---- | ------ | --- |
| K8ssandra Team | k8ssandra-developers@googlegroups.com | https://github.com/k8ssandra |

## Source Code

* <https://github.com/k8ssandra/k8ssandra>
* <https://github.com/k8ssandra/k8ssandra/tree/main/charts/k8ssandra>

## Requirements

| Repository | Name | Version |
|------------|------|---------|
| file://../cass-operator | cass-operator | 0.28.0 |
| file://../k8ssandra-common | k8ssandra-common | 0.28.0 |
| file://../medusa-operator | medusa-operator | 0.27.0 |
| file://../reaper-operator | reaper-operator | 0.29.0 |
| https://prometheus-community.github.io/helm-charts | kube-prometheus-stack | 12.11.3 |

## Values

| Key | Type | Default | Description |
|-----|------|---------|-------------|
| cassandra.version | string | `"3.11.10"` | The Cassandra version to use. The supported versions include the following:    - 3.11.7    - 3.11.8    - 3.11.9    - 3.11.10 |
| cassandra.versionImageMap | object | `{"3.11.10":"datastax/cassandra-mgmtapi-3_11_10:v0.1.19","3.11.7":"datastax/cassandra-mgmtapi-3_11_7:v0.1.19","3.11.8":"datastax/cassandra-mgmtapi-3_11_8:v0.1.19","3.11.9":"datastax/cassandra-mgmtapi-3_11_9:v0.1.19"}` | Specifies the image to use for a particular Cassandra version. Exercise care and caution with changing these values! cass-operator is not designed to work with arbitrary Cassandra images. It expects the cassandra container to be running management-api images. If you do want to change one of these mappings, the new value should be a management-api image. |
| cassandra.clusterName | string | `""` | Overrides the default image mappings. This is intended for advanced use cases like development or testing. By default the Cassandra version has to be one that is in versionImageMap. Template rendering will fail if the version is not in the map. When you set the image directly, the version mapping check is skipped. Note that you are still constrained to the versions supported by cass-operator. image: -- Cluster name defaults to release name when not specified. |
| cassandra.auth | object | `{"cacheUpdateIntervalMillis":3600000,"cacheValidityPeriodMillis":3600000,"enabled":true,"superuser":{"secret":"","username":""}}` | Authentication and authorization related settings. |
| cassandra.auth.enabled | bool | `true` | Enables or disables authentication and authorization |
| cassandra.auth.superuser | object | `{"secret":"","username":""}` | If neither superuser.secret nor superuser.username are set, then k8ssandra falls back to cass-operator's default behavior. cass-operator will create a default superuser and generate a secret whose name is of the form {clusterName}-superuser. If superuser.secret is set, k8ssandra will configure the CassandraDatacenter to use that secret. If superuser.secret is not set and if superuser.username is set, k8ssandra will generate a secret with the username and a random 20 character password. The secret generated by k8ssandra will have a name of the form {clusterName}-superuser. |
| cassandra.auth.cacheValidityPeriodMillis | int | `3600000` | Cache entries validity period in milliseconds. cassandra.yaml has settings for roles, permissions, and credentials caches. This property will configure the validity period for all three. |
| cassandra.auth.cacheUpdateIntervalMillis | int | `3600000` | Cache entries update period in milliseconds. cassandra.yaml has settings for roles, permissions, and credentials caches. This property will configure the update interval for all three. |
| cassandra.cassandraLibDirVolume.storageClass | string | `"standard"` | Storage class for persistent volume claims (PVCs) used by the underlying cassandra pods. Depending on your Kubernetes distribution this may be named "standard", "hostpath", or "localpath". Run `kubectl get storageclass` to identify what is available in your environment. |
| cassandra.cassandraLibDirVolume.size | string | `"5Gi"` | Size of the provisioned persistent volume per node. It is recommended to keep the total amount of data per node to approximately 1 TB. With room for compactions this value should max out at ~2 TB. This recommendation is highly dependent on data model and compaction strategies in use. Consider testing with your data model to find an optimal value for your usecase. |
| cassandra.allowMultipleNodesPerWorker | bool | `false` | Permits running multiple Cassandra pods per Kubernetes worker. If enabled resources.limits and resources.requests **must** be defined. |
| cassandra.heap | object | `{}` | Optional cluster-level heap configuration, can be overridden at `datacenters` level. Options are commented out for reference. |
| cassandra.resources | object | `{}` | Resource requests for each Cassandra pod. |
| cassandra.datacenters[0].name | string | `"dc1"` | Name of the datacenter |
| cassandra.datacenters[0].size | int | `1` | Number of nodes within the datacenter. This value should, at a minimum, match the number of racks and be no less than 3 for non-development environments. |
| cassandra.datacenters[0].racks | list | `[{"affinityLabels":{},"name":"default"}]` | Specifies the racks for the data center, if unset the datacenter will be composed of a single rack named `default`. The number of racks should equal the replication factor of your application keyspaces. Cassandra will ensure that replicas are spread across racks versus having multiple replicas within the same rack. For example, let's say we are using RF = 3 with a 9 node cluster and 3 racks (and 3 nodes per rack). There will be one replica of the dataset spread across each rack. |
| cassandra.datacenters[0].racks[0].name | string | `"default"` | Identifier for the rack, this may align with the labels used to control where resources are deployed for this rack. For example, if a rack is limited to a single availability zone the identifier may be the name of that AZ (eg us-east-1a). |
| cassandra.datacenters[0].racks[0].affinityLabels | object | `{}` | an optional set of labels that are used to pin Cassandra pods to specific k8s worker nodes via affinity rules. See https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/ for background on using affinity rules. topology.kubernetes.io/zone is a well-known k8s label used by cloud providers to indicate the failure zone in which a k8s worker node is running. The following example illustrates how you can pin racks to specific failure zones. |
| cassandra.datacenters[0].heap | object | `{}` | Optional datacenter-level heap setting, overrides cluster-level setting `cassandra.heap`.  Options are commented out for reference. |
| stargate.enabled | bool | `true` | Enable Stargate resources as part of this release |
| stargate.replicas | int | `1` | Number of Stargate instances to deploy. This value may be scaled independently of Cassandra cluster nodes. Each instance handles API and coordination tasks for inbound queries. |
| stargate.image | string | `nil` | Sets the Stargate container image. If left blank (recommended), k8ssandra will derive an appropriate image based on your cluster version. |
| stargate.imagePullPolicy | string | `"IfNotPresent"` | Sets the imagePullPolicy used by the Stargate pods |
| stargate.heapMB | int | `256` | Sets the heap size Stargate will use in megabytes. Memory request and limit for the pod will be set to this value x2 and x4, respectively. |
| stargate.cpuReqMillicores | int | `200` | Sets the CPU request for the Stargate pod in millicores. |
| stargate.cpuLimMillicores | int | `1000` | Sets the CPU limit for the Stargate pod in millicores. |
| stargate.cassandraUser | object | `{"secret":"","username":""}` | Configures the Cassandra user used by Stargate when authentication is enabled. If neither `cassandraUser.secret` nor `casandraUser.username` are set, then a Cassandra user and a secret will be created. The username will be `stargate`. The secret name will be of the form `{clusterName}-stargate`. The password will be a random 20 character password. If `cassandraUser.secret` is set, then the Cassandra user will be created from the contents of the secret. If `cassandraUser.secret` is not set and if `cassandraUser.username` is set, a secret will be generated using the specified username. The password will be generated as previously described. |
| repair.reaper.autoschedule | bool | `false` | When enabled, Reaper automatically sets up repair schedules for all non-system keypsaces. Repear monitors the cluster so that as keyspaces are added or removed repair schedules will be added or removed respectively. |
| repair.reaper.enabled | bool | `true` | Enable Reaper resources as part of this release. Note that Reaper uses Cassandra's JMX APIs to perform repairs. When Reaper is enabled, Cassandra will also be configured to allow remote JMX access. JMX authentication will be configured in Cassandra with credentials only created for Reaper in order to limit access. |
| repair.reaper.image.repository | string | `"docker.io/thelastpickle/cassandra-reaper"` | Specifies the container repository for cassandra-reaper |
| repair.reaper.image.tag | string | `"2.1.3"` | Tag of an image within the specified repository |
| repair.reaper.cassandraUser | object | `{"secret":"","username":""}` | Configures the Cassandra user used by Reaper when authentication is enabled. If neither cassandraUser.secret nor casandraUser.username are set, then a Cassandra user and a secret with the user's credentials will be created. The username will be reaper. The secret name will be of the form {clusterName}-reaper. The password will be a random 20 character password. If cassandraUser.secret is set, then the Cassandra user will be created from the contents of the secret. If cassandraUser.secret is not set and if cassandraUser.username is set, a secret will be generated using the specified username. The password will be generated as previously described. |
| repair.reaper.jmx | object | `{"password":"","username":""}` | Configures JMX access to the Cassandra cluster. Reaper requires remote JMX access to perform repairs. The Cassandra cluster will be configured with remote JMX access enabled when Reaper is deployed. The JMX access will be configured to use authentication. |
| repair.reaper.jmx.username | string | `""` | Username that Reaper will use for JMX access. If left blank a random, alphanumeric string will be generated. |
| repair.reaper.jmx.password | string | `""` | Password that Reaper will use for JMX access. If left blank a random, alphanumeric string will be generated. |
| backupRestore.medusa.enabled | bool | `false` | Enable Medusa resources as part of this release. If enabled, `bucketName` and `bucketSecret` **must** be defined. |
| backupRestore.medusa.image.repository | string | `"docker.io/k8ssandra/medusa"` | Specifies the container repository for Medusa |
| backupRestore.medusa.image.tag | string | `"6ab6a55541e9"` | Tag of an image within the specified repository |
| backupRestore.medusa.image.pullPolicy | string | `"IfNotPresent"` | The image pull policy |
| backupRestore.medusa.cassandraUser | object | `{"secret":"","username":""}` | Configures the Cassandra user used by Medusa when authentication is enabled. If neither `cassandraUser.secret` nor `casandraUser.username` are set, then a Cassandra user and a secret will be created. The username will be medusa. The secret name will be of the form {clusterName}-medusa. The password will be a random 20 character password. If `cassandraUser.secret` is set, then the Cassandra user will be created from the contents of the secret. If `cassandraUser.secret` is not set and if `cassandraUser.username` is set, a secret will be generated using the specified username. The password will be generated as previously described. |
| backupRestore.medusa.multiTenant | bool | `false` | Enables usage of a bucket across multiple clusters. |
| backupRestore.medusa.storage | string | `"s3"` | API interface used by the object store. Supported values include `s3` and `gcs` |
| backupRestore.medusa.bucketName | string | `""` | Name of the remote storage bucket where backups will be stored. |
| backupRestore.medusa.bucketSecret | string | `""` | Name of the Kubernetes `Secret` that stores the key file for the storage provider's API |
| ingress.traefik.enabled | bool | `false` | Enable Traefik custom resources as part of this release. |
| ingress.traefik.repair.enabled | bool | `true` | Enables Reaper Traefik ingress definitions. Note this will **only** work if `ingress.traefik.enabled` is also `true` |
| ingress.traefik.repair.entrypoints | list | `["web"]` | Traefik entrypoints where traffic is sourced. |
| ingress.traefik.repair.host | string | `"repair.k8ssandra.cluster.local"` | Hostname Traefik should use for routing requests to the repair UI. If using a local deployment consider leveraging dynamic DNS services like xip.io. Example: `repair.127.0.0.1.xip.io` will return `127.0.0.1` for DNS requests routing requests to your local machine. |
| ingress.traefik.cassandra.enabled | bool | `false` | Enables Cassandra Traefik ingress definitions. Note this will **only** work if `ingress.traefik.enabled` is also `true`. Additionally, this is mutually exclusive with ingress.traefik.stargate.cassandra.enabled |
| ingress.traefik.cassandra.entrypoints | list | `["cassandra"]` | Traefik entrypoints where traffic is sourced. |
| ingress.traefik.stargate.enabled | bool | `true` | Enables Stargate Traefik ingress definitions. Note this will **only** work if `stargate.enabled` and `ingress.traefik.enabled` are also `true`. Additionally, when enabled the authentication API (port 8081) is enabled automatically. |
| ingress.traefik.stargate.host | string | `"*"` | Hostname Traefik should use for routing requests to Stargate. If using a local deployment consider leveraging dynamic DNS services like xip.io. Example: `stargate.127.0.0.1.xip.io` will return `127.0.0.1` for DNS requests routing requests to your local machine. |
| ingress.traefik.stargate.graphql.enabled | bool | `true` | Enables ingress resources for Stargate GraphQL API. Note this will **only** work if `stargate.enabled`, `ingress.traefik.enabled`, and `ingress.traefik.stargate.enabled` are also `true` |
| ingress.traefik.stargate.graphql.playground.enabled | bool | `true` | Enables GraphQL playground interface ingress. |
| ingress.traefik.stargate.rest.enabled | bool | `true` | Enables ingress resources for Stargate REST API. Note this will **only** work if `stargate.enabled`, `ingress.traefik.enabled`, and `ingress.traefik.stargate.enabled` are also `true` |
| ingress.traefik.stargate.cassandra.enabled | bool | `true` | Enables Traefik ingress resources for Stargate Cassandra API. Note this will **only** work if `stargate.enabled`, `ingress.traefik.enabled`, and `ingress.traefik.stargate.enabled` are also `true`. Additionally, this is mutually exclusive with ingress.traefik.cassandra.enabled |
| ingress.traefik.stargate.cassandra.entrypoints[0] | string | `"cassandra"` |  |
| monitoring.grafana.provision_dashboards | bool | `true` | Enables the creation of configmaps containing Grafana dashboards. If leveraging the kube prometheus stack sub-chart this value should be `true`. |
| monitoring.prometheus.provision_service_monitors | bool | `true` | Enabes the creation of Prometheus Operator ServiceMonitor custom resources. If you are not using the kube prometheus stack sub-chart or do not have the ServiceMonitor CRD installed on your cluster, set this value to `false`. |
| cleaner.image | string | `"k8ssandra/k8ssandra-cleaner:618b8ff9d368"` |  |
| cass-operator.enabled | bool | `true` | Enables the cass-operator as part of this release. If this setting is disabled no Cassandra resources will be deployed. |
| reaper-operator.enabled | bool | `true` | Enables the reaper-operator as part of this release. If this setting is disabled no repair resources will be deployed. |
| kube-prometheus-stack.enabled | bool | `true` | Controls whether the kube-prometheus-stack chart is used at all. Disabling this parameter prevents all monitoring components from being installed. |
| kube-prometheus-stack.coreDns.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeApiServer.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeControllerManager.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeDns.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeEtcd.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeProxy.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeScheduler.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeStateMetrics.enabled | bool | `false` |  |
| kube-prometheus-stack.kubelet.enabled | bool | `false` |  |
| kube-prometheus-stack.nodeExporter.enabled | bool | `false` |  |
| kube-prometheus-stack.alertmanager.enabled | bool | `false` |  |
| kube-prometheus-stack.alertmanager.serviceMonitor.selfMonitor | bool | `false` |  |
| kube-prometheus-stack.prometheusOperator.enabled | bool | `true` |  |
| kube-prometheus-stack.prometheusOperator.namespaces | object | `{"additional":[],"releaseNamespace":true}` | Locks Prometheus operator to this namespace. Changing this setting may result in a non-namespace scoped deployment. |
| kube-prometheus-stack.prometheusOperator.serviceMonitor | object | `{"selfMonitor":false}` | Monitoring of prometheus operator |
| kube-prometheus-stack.prometheus.enabled | bool | `true` | Provisions an instance of Prometheus as part of this release |
| kube-prometheus-stack.prometheus.prometheusSpec | object | `{"externalUrl":"","routePrefix":"/"}` | Allows for tweaking of the Prometheus installation's configuration. Common parameters include `externalUrl: http://localhost:9090/prometheus` and `routePrefix: /prometheus` for running Prometheus resources under a specific path (`/prometheus` in this example). |
| kube-prometheus-stack.prometheus.prometheusSpec.routePrefix | string | `"/"` | Prefixes all Prometheus routes with the specified value. It is useful for ingresses which do not rewrite URLs. |
| kube-prometheus-stack.prometheus.prometheusSpec.externalUrl | string | `""` | An external URL at which Prometheus will be reachable. |
| kube-prometheus-stack.prometheus.ingress.enabled | bool | `false` | Enable templating of ingress resources for external prometheus traffic |
| kube-prometheus-stack.prometheus.ingress.paths | list | `[]` | Path-based routing rules, `/prometheus` is possible if the appropriate changes are made to `prometheusSpec` |
| kube-prometheus-stack.prometheus.serviceMonitor.selfMonitor | bool | `false` |  |
| kube-prometheus-stack.grafana.enabled | bool | `true` | Provisions an instance of Grafana and wires it up with a DataSource referencing this Prometheus installation |
| kube-prometheus-stack.grafana.ingress.enabled | bool | `false` | Generates ingress resources for the Grafana instance |
| kube-prometheus-stack.grafana.ingress.path | string | `nil` | Path-based routing rules, '/grafana' is possible if appropriate changes are made to `grafana.ini` |
| kube-prometheus-stack.grafana.adminUser | string | `"admin"` | Username for accessing the provisioned Grafana instance |
| kube-prometheus-stack.grafana.adminPassword | string | `"secret"` | Password for accessing the provisioned Grafana instance |
| kube-prometheus-stack.grafana.serviceMonitor.selfMonitor | bool | `false` | Whether the Grafana instance should be monitored |
| kube-prometheus-stack.grafana.defaultDashboardsEnabled | bool | `false` | Default dashboard installation |
| kube-prometheus-stack.grafana.plugins | list | `["grafana-polystat-panel"]` | Additional plugins to be installed during Grafana startup, `grafana-polystat-panel` is used by the default Cassandra dashboards. |
| kube-prometheus-stack.grafana."grafana.ini" | object | `{}` | Customization of the Grafana instance. To listen for Grafana traffic under a different url set `server.root_url: http://localhost:3000/grafana` and `serve_from_sub_path: true`. |
