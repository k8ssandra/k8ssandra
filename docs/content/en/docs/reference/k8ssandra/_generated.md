

![Version: 0.38.0](https://img.shields.io/badge/Version-0.38.0-informational?style=flat-square) ![Type: application](https://img.shields.io/badge/Type-application-informational?style=flat-square) ![AppVersion: 3.11.7](https://img.shields.io/badge/AppVersion-3.11.7-informational?style=flat-square)

## Maintainers

| Name | Email | Url |
| ---- | ------ | --- |
| K8ssandra Team | k8ssandra-developers@googlegroups.com | https://github.com/k8ssandra |

## Source Code

* <https://github.com/k8ssandra/k8ssandra>
* <https://github.com/k8ssandra/k8ssandra/tree/main/charts/k8ssandra>

## Requirements

| Repository | Name | Version |
|------------|------|---------|
| file://../cass-operator | cass-operator | 0.28.0 |
| file://../k8ssandra-common | k8ssandra-common | 0.28.0 |
| file://../medusa-operator | medusa-operator | 0.27.0 |
| file://../reaper-operator | reaper-operator | 0.28.0 |
| https://prometheus-community.github.io/helm-charts | kube-prometheus-stack | 12.11.3 |

## Values

| Key | Type | Default | Description |
|-----|------|---------|-------------|
| cassandra.version | string | `"3.11.9"` | Version of Apache Cassandra to deploy |
| cassandra.clusterName | string | `"k8ssandra"` | Cassandra cluster_name parameter in cassandra.yaml |
| cassandra.auth.enabled | bool | `true` | Enables or disables authentication and authorization |
| cassandra.auth.superuser | object | `{"secret":"","username":""}` | If neither superuser.secret nor superuser.username are set, then k8ssandra falls back to cass-operator's default behavior. cass-operator will create a default superuser and generate a secret whose name is of the form {clusterName}-superuser. If superuser.secret is set, k8ssandra will configure the CassandraDatacenter to use that secret. If superuser.secret is not set and if superuser.username is set, k8ssandra will generate a secret with the username and a random 20 character password. The secret generated by k8ssandra will have a name of the form {clusterName}-superuser. |
| cassandra.auth.cacheValidityPeriodMillis | int | `3600000` | Cache entries validitity period in milliseconds. cassandra.yaml has settings for roles, permissions, and credentials caches. This property will configure the validity period for all three. |
| cassandra.auth.cacheUpdateIntervalMillis | int | `3600000` | Cache entries update period in milliseconds. cassandra.yaml has settings for roles, permissions, and credentials caches. This property will configure the update interval for all three. |
| cassandra.cassandraLibDirVolume.storageClass | string | `"standard"` | Storage class for persistent volume claims (PVCs) used by the underlying cassandra pods. Depending on your Kubernetes distribution this may be named "standard", "hostpath", or "localpath". Run `kubectl get storageclass` to identify what is available in your environment. |
| cassandra.cassandraLibDirVolume.size | string | `"5Gi"` | Size of the provisioned persistent volume per node. It is recommended to keep the total amount of data per node to approximately 1 TB. With room for compactions this value should max out at ~2 TB. This recommendation is highly dependent on data model and compaction strategies in use. Consider testing with your data model to find an optimal value for your usecase.  |
| cassandra.allowMultipleNodesPerWorker | bool | `false` | Permits running multiple Cassandra pods per Kubernetes worker. If enabled resources.limits and resources.requests **must** be defined. |
| cassandra.heap | object | `{"newGenSize":"400M","size":"800M"}` | Cluster-level heap configuration |
| cassandra.resources | object | `{}` | Resource requests for each Cassandra pod. |
| cassandra.datacenters[0].name | string | `"dc1"` | Name of the datacenter |
| cassandra.datacenters[0].size | int | `1` | Number of nodes within the datacenter. This value should, at a minimum, match the number of racks and be no less than 3 for non-development environments. |
| cassandra.datacenters[0].racks | list | `[{"affinityLabels":{},"name":"default"}]` | Specifies the racks for the data center, if unset the datacenter will be composed of a single rack named `default`. The number of racks should equal the replication factor of your application keyspaces. Cassandra will ensure that replicas are spread across racks versus having multiple replicas within the same rack. For example, let's say we are using RF = 3 with a 9 node cluster and 3 racks (and 3 nodes per rack). There will be one replica of the dataset spread across each rack. |
| cassandra.datacenters[0].racks[0].name | string | `"default"` | Identifier for the rack, this may align with the labels used to control where resources are deployed for this rack. For example, if a rack is limited to a single availability zone the identifier may be the name of that AZ (eg us-east-1a). |
| cassandra.datacenters[0].racks[0].affinityLabels | object | `{}` | an optional set of labels that are used to pin Cassandra pods to specific k8s worker nodes via affinity rules. See https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/ for background on using affinity rules. topology.kubernetes.io/zone is a well-known k8s label used by cloud providers to indicate the failure zone in which a k8s worker node is running. The following example illustrates how you can pin racks to specific failure zones. |
| cassandra.datacenters[0].heap | object | `{"newGenSize":"400M","size":"800M"}` | Optional datacenter-level heap setting, overrides cluster-level setting `cassandra.heap` |
| stargate.enabled | bool | `false` | Enable Stargate resources as part of this release |
| stargate.replicas | int | `1` | Number of instances to deploy. This value may be scaled independently of Cassandra cluster nodes. Each instance handles API and coordination tasks for inbound queries. |
| stargate.clusterVersion | string | `"3.11"` | Version of the target Cassandra cluster. `3.11` is the only supported value for now. |
| stargate.containerImage | string | `"auto"` | Image coordinate for Stargate containers, `auto` will determine the appropriate value based on other configuration parameters. |
| repair.reaper.autoschedule | bool | `false` |  |
| repair.reaper.enabled | bool | `true` | Enable Reaper resources as part of this release |
| repair.reaper.cassandraUser | object | `{"secret":"","username":""}` | Configures the Cassandra user used by Reaper when authentication is enabled. If neither cassandraUser.secret nor casandraUser.username are set, then a Cassandra user and a secret with the user's credentials will be created. The username will be reaper. The secret name will be of the form {cluserName}-reaper. The password will be a random 20 character password. If cassandraUser.secret is set, then the Cassandra user will be created from the contents of the secret. If cassandraUser.secret is not set and if cassandraUser.username is set, a secret will be generated using the specified username. The password will be generated as previously described. |
| repair.reaper.jmx | object | `{"password":"","username":""}` | JMX authentication parameters for use by Reaper to trigger repair tasks |
| backupRestore.medusa.enabled | bool | `false` | Enable Medusa resources as part of this release. If enabled, `bucketName` and `bucketSecret` **must** be defined. |
| backupRestore.medusa.image | string | `"k8ssandra/medusa:c5fefc4a3b4c"` |  |
| backupRestore.medusa.cassandraUser | object | `{"secret":"","username":""}` | Configures the Cassandra user used by Medusa when authentication is enabled. If neither `cassandraUser.secret` nor `casandraUser.username` are set, then a Cassandra user and a secret will be created. The username will be medusa. The secret name will be of the form {cluserName}-medusa. The password will be a random 20 character password. If `cassandraUser.secret` is set, then the Cassandra user will be created from the contents of the secret. If `cassandraUser.secret` is not set and if `cassandraUser.username` is set, a secret will be generated using the specified username. The password will be generated as previously described. |
| backupRestore.medusa.multiTenant | bool | `false` | Enables usage of a bucket across multiple clusters. |
| backupRestore.medusa.storage | string | `"s3"` | API interface used by the object store. Supported values include `s3` and `gcs` |
| backupRestore.medusa.bucketName | string | `""` | Name of the remote storage bucket where backups will be stored. |
| backupRestore.medusa.bucketSecret | string | `""` | Name of the Kubernetes `Secret` that stores the key file for the storage provider's API |
| ingress.traefik.enabled | bool | `false` | Enable Traefik custom resources as part of this release. |
| ingress.traefik.repair.enabled | bool | `true` | Enables Reaper Traefik ingress definitions. Note this will **only** work if `ingress.traefik.enabled` is also `true` |
| ingress.traefik.repair.entrypoints | list | `["web"]` | Traefik entrypoints where traffic is sourced. |
| ingress.traefik.repair.host | string | `"repair.k8ssandra.cluster.local"` | Hostname Traefik should use for routing requests to the repair UI. If using a local deployment consider leveraging dynamic DNS services like xip.io. Example: `repair.127.0.0.1.xip.io` will return `127.0.0.1` for DNS requests routing requests to your local machine. |
| ingress.traefik.cassandra.enabled | bool | `true` | Enables Cassandra Traefik ingress definitions. Note this will **only** work if `ingress.traefik.enabled` is also `true`. Additionally, this is mutually exclusive with ingress.traefik.stargate.cassandra.enabled |
| ingress.traefik.cassandra.entrypoints | list | `["cassandra"]` | Traefik entrypoints where traffic is sourced. |
| ingress.traefik.stargate.enabled | bool | `false` | Enables Stargate Traefik ingress definitions. Note this will **only** work if `ingress.traefik.enabled` is also `true`. Additionally, when enabled the authentication API (port 8081) is enabled automatically. |
| ingress.traefik.stargate.host | string | `"stargate.k8ssandra.cluster.local"` | Hostname Traefik should use for routing requests to the repair UI. If using a local deployment consider leveraging dynamic DNS services like xip.io. Example: `repair.127.0.0.1.xip.io` will return `127.0.0.1` for DNS requests routing requests to your local machine. |
| ingress.traefik.stargate.graphql.enabled | bool | `true` | Enables ingress resources for Stargate GraphQL API. Note this will **only** work if `stargate.enabled`, `ingress.traefik.enabled`, and `ingress.traefik.stargate.enabled` are also `true` |
| ingress.traefik.stargate.graphql.playground.enabled | bool | `false` | Enables GraphQL playground interface ingress. |
| ingress.traefik.stargate.rest.enabled | bool | `true` | Enables ingress resources for Stargate REST API. Note this will **only** work if `stargate.enabled`, `ingress.traefik.enabled`, and `ingress.traefik.stargate.enabled` are also `true` |
| ingress.traefik.stargate.cassandra.enabled | bool | `false` | Enables Traefik ingress resources for Stargate Cassandra API. Note this will **only** work if `stargate.enabled`, `ingress.traefik.enabled`, and `ingress.traefik.stargate.enabled` are also `true`. Additionally, this is mutually exclusive with ingress.traefik.cassandra.enabled |
| ingress.traefik.stargate.cassandra.entrypoints[0] | string | `"cassandra"` |  |
| monitoring.grafana.provision_dashboards | bool | `true` | Enables the creation of configmaps containing Grafana dashboards. If leveraging the kube prometheus stack sub-chart this value should be `true`. |
| monitoring.prometheus.provision_service_monitors | bool | `true` | Enabes the creation of Prometheus Operator ServiceMonitor custom resources. If you are not using the kube prometheus stack sub-chart or do not have the ServiceMonitor CRD installed on your cluster, set this value to `false`. |
| cleaner.image | string | `"k8ssandra/k8ssandra-cleaner:618b8ff9d368"` |  |
| cass-operator.enabled | bool | `true` | Enables the cass-operator as part of this release. If this setting is disabled no Cassandra resources will be deployed. |
| reaper-operator.enabled | bool | `true` | Enables the reaper-operator as part of this release. If this setting is disabled no repair resources will be deployed. |
| kube-prometheus-stack.enabled | bool | `true` | Controls whether the kube-prometheus-stack chart is used at all. Disabling this parameter prevents all monitoring components from being installed. |
| kube-prometheus-stack.coreDns.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeApiServer.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeControllerManager.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeDns.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeEtcd.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeProxy.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeScheduler.enabled | bool | `false` |  |
| kube-prometheus-stack.kubeStateMetrics.enabled | bool | `false` |  |
| kube-prometheus-stack.kubelet.enabled | bool | `false` |  |
| kube-prometheus-stack.nodeExporter.enabled | bool | `false` |  |
| kube-prometheus-stack.alertmanager.enabled | bool | `false` |  |
| kube-prometheus-stack.alertmanager.serviceMonitor.selfMonitor | bool | `false` |  |
| kube-prometheus-stack.prometheusOperator.enabled | bool | `true` |  |
| kube-prometheus-stack.prometheusOperator.namespaces | object | `{"additional":[],"releaseNamespace":true}` | Locks Prometheus operator to this namespace. Changing this setting may result in a non-namespace scoped deployment. |
| kube-prometheus-stack.prometheusOperator.serviceMonitor | object | `{"selfMonitor":false}` | Monitoring of prometheus operator |
| kube-prometheus-stack.prometheus.enabled | bool | `true` | Provisions an instance of Prometheus as part of this release |
| kube-prometheus-stack.prometheus.prometheusSpec | object | `{}` | Allows for tweaking of the Prometheus installation's configuration. Common parameters include `externalUrl: http://localhost:9090/prometheus` and `routePrefix: /prometheus` for running Prometheus resources under a specific path (`/prometheus` in this example). |
| kube-prometheus-stack.prometheus.ingress.enabled | bool | `false` | Enable templating of ingress resources for external prometheus traffic |
| kube-prometheus-stack.prometheus.ingress.paths | list | `[]` | Path-based routing rules, `/prometheus` is possible if the appropriate changes are made to `prometheusSpec` |
| kube-prometheus-stack.prometheus.serviceMonitor.selfMonitor | bool | `false` |  |
| kube-prometheus-stack.grafana.enabled | bool | `true` | Provisions an instance of Grafana and wires it up with a DataSource referencing this Prometheus installation |
| kube-prometheus-stack.grafana.ingress.enabled | bool | `false` | Generates ingress resources for the Grafana instance |
| kube-prometheus-stack.grafana.ingress.path | string | `nil` | Path-based routing rules, '/grafana' is possible if appropriate changes are made to `grafana.ini` |
| kube-prometheus-stack.grafana.adminUser | string | `"admin"` | Username for accessing the provisioned Grafana instance |
| kube-prometheus-stack.grafana.adminPassword | string | `"secret"` | Password for accessing the provisioned Grafana instance |
| kube-prometheus-stack.grafana.serviceMonitor.selfMonitor | bool | `false` | Whether the Grafana instance should be monitored |
| kube-prometheus-stack.grafana.defaultDashboardsEnabled | bool | `false` | Default dashboard installation |
| kube-prometheus-stack.grafana.plugins | list | `["grafana-polystat-panel"]` | Additional plugins to be installed during Grafana startup, `grafana-polystat-panel` is used by the default Cassandra dashboards. |
| kube-prometheus-stack.grafana."grafana.ini" | object | `{}` | Customization of the Grafana instance. To listen for Grafana traffic under a different url set `server.root_url: http://localhost:3000/grafana` and `serve_from_sub_path: true`. |
